{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3444a841",
   "metadata": {},
   "source": [
    "# Prediksi Hasil Panen dengan Machine Learning & Deep Learning\n",
    "\n",
    "Notebook ini berisi seluruh kode dari `main.py` yang telah dibagi menjadi beberapa section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198eab96",
   "metadata": {},
   "source": [
    "# Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b97856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "rcParams[\"figure.figsize\"] = 15, 7\n",
    "sns.set(palette=\"Set2\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a7cb9",
   "metadata": {},
   "source": [
    "# Memuat dan Memeriksa Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da78672b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran awal dataset: (28242, 8)\n"
     ]
    }
   ],
   "source": [
    "pred_csv_path = \"dataset/yield_df.csv\"\n",
    "\n",
    "x = pd.read_csv(pred_csv_path)\n",
    "x.head()\n",
    "\n",
    "data = pd.read_csv(pred_csv_path)\n",
    "print(f\"Ukuran awal dataset: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046086b3",
   "metadata": {},
   "source": [
    "# Data Preprocessing dan Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d876ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, col):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    mask = (df[col] >= Q1 - 1.5 * IQR) & (df[col] <= Q3 + 1.5 * IQR)\n",
    "    return df[mask]\n",
    "\n",
    "features = ['avg_temp', 'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'rolling_yield_mean3']\n",
    "target = 'log_yield'\n",
    "look_back = 9\n",
    "\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefe7d7c",
   "metadata": {},
   "source": [
    "# Pembuatan urutan untuk Time Series Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc37550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences_all(data, features, target, look_back=9):\n",
    "    X, y = [], []\n",
    "    areas = data['Area'].unique()\n",
    "    for area in areas:\n",
    "        region_data = data[data['Area'] == area].sort_values('Year')\n",
    "        for i in range(look_back, len(region_data)):\n",
    "            X.append(region_data[features].iloc[i-look_back:i].values)\n",
    "            y.append(region_data[target].iloc[i])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e38955",
   "metadata": {},
   "source": [
    "# Inisialisasi kamus scaler untuk fitur dan target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174449c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa3006",
   "metadata": {},
   "source": [
    "# Membuat kolom log_yield, rolling_yield_mean3, dan scaling fitur/target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb89835",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_yield'] = np.log(data['hg/ha_yield'] + 1)\n",
    "data['rolling_yield_mean3'] = data.groupby('Area')['hg/ha_yield'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "\n",
    "scaler_rolling = MinMaxScaler()\n",
    "data['rolling_yield_mean3'] = scaler_rolling.fit_transform(data[['rolling_yield_mean3']])\n",
    "\n",
    "for col in features:\n",
    "    scaler = MinMaxScaler()\n",
    "    data[col] = scaler.fit_transform(data[[col]])\n",
    "    scaler_dict[col] = scaler\n",
    "\n",
    "target_scaler = MinMaxScaler()\n",
    "data[target] = target_scaler.fit_transform(data[[target]])\n",
    "scaler_dict[target] = target_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7392eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membuat sequence data untuk training dan testing...\n",
      "Jumlah data training: 19133\n",
      "Jumlah data testing: 8200\n",
      "Jumlah data training: 19133\n",
      "Jumlah data testing: 8200\n"
     ]
    }
   ],
   "source": [
    "print(\"Membuat sequence data untuk training dan testing...\")\n",
    "X, y = create_sequences_all(data, features, target, look_back=look_back)\n",
    "X_rf = X.reshape(X.shape[0], -1)  # Untuk model tree-based\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Jumlah data training: {X_train.shape[0]}\")\n",
    "print(f\"Jumlah data testing: {X_test.shape[0]}\")\n",
    "X_train_rf = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_rf = X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259f706c",
   "metadata": {},
   "source": [
    "# Inisiasi grid parameter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5564f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_param_grid = {\n",
    "    'model__units': [32, 64],\n",
    "    'model__dropout': [0.1, 0.2, 0.3],\n",
    "    'model__lr': [0.001, 0.0005],\n",
    "    'batch_size': [8, 16],\n",
    "    'epochs': [50],\n",
    "}\n",
    "lstm_param_grid = {\n",
    "    'model__units1': [32, 64],\n",
    "    'model__units2': [16, 32],\n",
    "    'model__dropout': [0.1, 0.2, 0.3],\n",
    "    'model__lr': [0.001, 0.0005],\n",
    "    'batch_size': [8, 16],\n",
    "    'epochs': [50],\n",
    "}\n",
    "gru_param_grid = {\n",
    "    'model__units1': [32, 64],\n",
    "    'model__units2': [16, 32],\n",
    "    'model__dropout': [0.1, 0.2, 0.3],\n",
    "    'model__lr': [0.001, 0.0005],\n",
    "    'batch_size': [8, 16],\n",
    "    'epochs': [50],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aab4483",
   "metadata": {},
   "source": [
    "## Train & Evaluasi SimpleRNN\n",
    "Training dan evaluasi model SimpleRNN pada data hasil split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9eab29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] GridSearchCV SimpleRNN...\n",
      "[INFO] SimpleRNN selesai training. Evaluasi...\n",
      "[INFO] Evaluasi SimpleRNN selesai.\n"
     ]
    }
   ],
   "source": [
    "def build_rnn_model(units=64, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        SimpleRNN(units, activation='tanh'),\n",
    "        Dropout(dropout),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "print(\"[INFO] GridSearchCV SimpleRNN...\")\n",
    "rnn_reg = KerasRegressor(model=build_rnn_model, verbose=0)\n",
    "rnn_grid = GridSearchCV(rnn_reg, rnn_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "rnn_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] SimpleRNN selesai training. Evaluasi...\")\n",
    "rnn_best = rnn_grid.best_estimator_\n",
    "y_pred = rnn_best.predict(X_test)\n",
    "y_pred = y_pred.reshape(-1, 1)\n",
    "y_pred = y_pred if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_pred)\n",
    "y_true = y_test.reshape(-1, 1)\n",
    "y_true = y_true if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_true)\n",
    "all_results.append({\n",
    "    'item': 'ALL',\n",
    "    'model': 'SimpleRNN',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rnn_grid.best_params_)\n",
    "})\n",
    "print(\"[INFO] Evaluasi SimpleRNN selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee0052",
   "metadata": {},
   "source": [
    "## Train & Evaluasi LSTM\n",
    "Training dan evaluasi model LSTM pada data hasil split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eb187f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] GridSearchCV LSTM...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m lstm_reg = KerasRegressor(model=build_lstm_model, verbose=\u001b[32m0\u001b[39m)\n\u001b[32m     15\u001b[39m lstm_grid = GridSearchCV(lstm_reg, lstm_param_grid, cv=\u001b[32m3\u001b[39m, scoring=\u001b[33m'\u001b[39m\u001b[33mneg_mean_absolute_error\u001b[39m\u001b[33m'\u001b[39m, n_jobs=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mlstm_grid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[INFO] LSTM selesai training. Evaluasi...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m lstm_best = lstm_grid.best_estimator_\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/sklearn/utils/parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:859\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    857\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    862\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    863\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/scikeras/wrappers.py:770\u001b[39m, in \u001b[36mBaseWrapper.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, **kwargs)\u001b[39m\n\u001b[32m    765\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.get(\n\u001b[32m    766\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfit__epochs\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.epochs)\n\u001b[32m    767\u001b[39m )\n\u001b[32m    768\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33minitial_epoch\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33minitial_epoch\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    772\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    773\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/scikeras/wrappers.py:938\u001b[39m, in \u001b[36mBaseWrapper._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[39m\n\u001b[32m    934\u001b[39m X = \u001b[38;5;28mself\u001b[39m.feature_encoder_.transform(X)\n\u001b[32m    936\u001b[39m \u001b[38;5;28mself\u001b[39m._check_model_compatibility(y)\n\u001b[32m--> \u001b[39m\u001b[32m938\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_keras_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/scikeras/wrappers.py:535\u001b[39m, in \u001b[36mBaseWrapper._fit_keras_model\u001b[39m\u001b[34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[39m\n\u001b[32m    533\u001b[39m         hist = \u001b[38;5;28mself\u001b[39m.model_.fit(x=X, y=y, **fit_args)\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     hist = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhistory_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m initial_epoch == \u001b[32m0\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28mself\u001b[39m.history_ = defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01. kuliah/01. semester 7/01. project/04. ta/02. repo/-deep-learning-crop-prediction/venv/lib/python3.13/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def build_lstm_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        LSTM(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        LSTM(units2, activation='tanh'),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "print(\"[INFO] GridSearchCV LSTM...\")\n",
    "lstm_reg = KerasRegressor(model=build_lstm_model, verbose=0)\n",
    "lstm_grid = GridSearchCV(lstm_reg, lstm_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "lstm_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] LSTM selesai training. Evaluasi...\")\n",
    "lstm_best = lstm_grid.best_estimator_\n",
    "y_pred = lstm_best.predict(X_test)\n",
    "y_pred = y_pred.reshape(-1, 1)\n",
    "y_pred = y_pred if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_pred)\n",
    "y_true = y_test.reshape(-1, 1)\n",
    "y_true = y_true if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_true)\n",
    "all_results.append({\n",
    "    'item': 'ALL',\n",
    "    'model': 'LSTM',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(lstm_grid.best_params_)\n",
    "})\n",
    "print(\"[INFO] Evaluasi LSTM selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dd57c2",
   "metadata": {},
   "source": [
    "## Train & Evaluasi GRU\n",
    "Training dan evaluasi model GRU pada data hasil split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85863f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gru_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        GRU(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        GRU(units2),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "print(\"[INFO] GridSearchCV GRU...\")\n",
    "gru_reg = KerasRegressor(model=build_gru_model, verbose=0)\n",
    "gru_grid = GridSearchCV(gru_reg, gru_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "gru_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] GRU selesai training. Evaluasi...\")\n",
    "gru_best = gru_grid.best_estimator_\n",
    "y_pred = gru_best.predict(X_test)\n",
    "y_pred = y_pred.reshape(-1, 1)\n",
    "y_pred = y_pred if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_pred)\n",
    "y_true = y_test.reshape(-1, 1)\n",
    "y_true = y_true if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_true)\n",
    "all_results.append({\n",
    "    'item': 'ALL',\n",
    "    'model': 'GRU',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gru_grid.best_params_)\n",
    "})\n",
    "print(\"[INFO] Evaluasi GRU selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54077207",
   "metadata": {},
   "source": [
    "## Train & Evaluasi RandomForest\n",
    "Training dan evaluasi model RandomForest pada data hasil split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV RandomForest...\")\n",
    "rf_grid = GridSearchCV(rf, rf_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] RandomForest selesai training. Evaluasi...\")\n",
    "rf_best = rf_grid.best_estimator_\n",
    "y_pred = rf_best.predict(X_test_rf)\n",
    "y_pred = y_pred.reshape(-1, 1)\n",
    "y_pred = y_pred if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_pred)\n",
    "y_true = y_test.reshape(-1, 1)\n",
    "y_true = y_true if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_true)\n",
    "all_results.append({\n",
    "    'item': 'ALL',\n",
    "    'model': 'RandomForest',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rf_grid.best_params_)\n",
    "})\n",
    "print(\"[INFO] Evaluasi RandomForest selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d63b33",
   "metadata": {},
   "source": [
    "## Train & Evaluasi BaggingRegressor\n",
    "Training dan evaluasi model BaggingRegressor pada data hasil split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c2fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_param_grid = {\n",
    "    'estimator': [RandomForestRegressor(max_depth=3), RandomForestRegressor(max_depth=5)],\n",
    "    'n_estimators': [10, 20, 50]\n",
    "}\n",
    "bag = BaggingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV BaggingRegressor...\")\n",
    "bag_grid = GridSearchCV(bag, bag_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] BaggingRegressor selesai training. Evaluasi...\")\n",
    "bag_best = bag_grid.best_estimator_\n",
    "y_pred = bag_best.predict(X_test_rf)\n",
    "y_pred = y_pred.reshape(-1, 1)\n",
    "y_pred = y_pred if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_pred)\n",
    "y_true = y_test.reshape(-1, 1)\n",
    "y_true = y_true if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_true)\n",
    "all_results.append({\n",
    "    'item': 'ALL',\n",
    "    'model': 'BaggingRegressor',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(bag_grid.best_params_)\n",
    "})\n",
    "print(\"[INFO] Evaluasi BaggingRegressor selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cf65b3",
   "metadata": {},
   "source": [
    "## Train & Evaluasi GradientBoosting\n",
    "Training dan evaluasi model GradientBoosting pada data hasil split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ffeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV GradientBoostingRegressor...\")\n",
    "gb_grid = GridSearchCV(gb, gb_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "gb_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] GradientBoostingRegressor selesai training. Evaluasi...\")\n",
    "gb_best = gb_grid.best_estimator_\n",
    "y_pred = gb_best.predict(X_test_rf)\n",
    "y_pred = y_pred.reshape(-1, 1)\n",
    "y_pred = y_pred if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_pred)\n",
    "y_true = y_test.reshape(-1, 1)\n",
    "y_true = y_true if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_true)\n",
    "all_results.append({\n",
    "    'item': 'ALL',\n",
    "    'model': 'GradientBoosting',\n",
    "    'category': 'Boosting',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gb_grid.best_params_)\n",
    "})\n",
    "print(\"[INFO] Evaluasi GradientBoostingRegressor selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1440bb9f",
   "metadata": {},
   "source": [
    "# Visualisasi Hasil Evaluasi Model\n",
    "Bagian ini menampilkan berbagai visualisasi hasil evaluasi model, seperti distribusi yield, heatmap korelasi, boxplot, dan perbandingan performa model (R2 dan MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7aefb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results/all_models'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# 1. Histogram Yield\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(data['hg/ha_yield'], bins=30, kde=True, color='skyblue')\n",
    "plt.title('Distribusi Yield (hg/ha_yield)')\n",
    "plt.xlabel('Yield (hg/ha)')\n",
    "plt.ylabel('Frekuensi')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '1_hist_yield_distribution.png'))\n",
    "plt.close()\n",
    "\n",
    "# 2. Korelasi Heatmap\n",
    "plt.figure(figsize=(10,8))\n",
    "num_cols = data.select_dtypes(include='number').columns\n",
    "corr = data[num_cols].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', square=True)\n",
    "plt.title('Heatmap Korelasi Fitur Numerik')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '2_heatmap_korelasi.png'))\n",
    "plt.close()\n",
    "\n",
    "# 3. Jumlah Data per Area (Encoded)\n",
    "plt.figure(figsize=(14,6))\n",
    "area_counts = data['Area'].value_counts().sort_values(ascending=False)\n",
    "sns.barplot(x=area_counts.index, y=area_counts.values, palette='viridis')\n",
    "plt.title('Jumlah Data per Area')\n",
    "plt.xlabel('Area (Encoded)')\n",
    "plt.ylabel('Jumlah Data')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '3_countplot_area.png'))\n",
    "plt.close()\n",
    "\n",
    "# 4. Boxplot Yield per Crop\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x='Item', y='hg/ha_yield', data=data, palette='Set2')\n",
    "plt.title('Boxplot Yield per Crop')\n",
    "plt.xlabel('Crop (Item)')\n",
    "plt.ylabel('Yield (hg/ha)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '4_boxplot_yield_per_crop.png'))\n",
    "plt.close()\n",
    "\n",
    "# 5. R² Score Tiap Model per Crop\n",
    "df_results = pd.DataFrame(all_results)\n",
    "plt.figure(figsize=(14,7))\n",
    "sns.barplot(data=df_results, x='item', y='r2', hue='model', ci=None)\n",
    "plt.title('R² Score Tiap Model per Crop')\n",
    "plt.ylabel('R² Score')\n",
    "plt.xlabel('Crop (Item)')\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '5_r2score_per_model_crop.png'))\n",
    "plt.close()\n",
    "\n",
    "# 6. Rata-rata R² Score per Model\n",
    "plt.figure(figsize=(10,6))\n",
    "avg_r2 = df_results.groupby('model')['r2'].mean().sort_values(ascending=False)\n",
    "sns.barplot(x=avg_r2.index, y=avg_r2.values, palette='Blues_d')\n",
    "plt.title('Rata-rata R² Score per Model')\n",
    "plt.ylabel('Rata-rata R²')\n",
    "plt.xlabel('Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '6_avg_r2_score_per_model.png'))\n",
    "plt.close()\n",
    "\n",
    "# 7. Rata-rata MAE per Model\n",
    "plt.figure(figsize=(10,6))\n",
    "avg_mae = df_results.groupby('model')['mae'].mean().sort_values()\n",
    "sns.barplot(x=avg_mae.index, y=avg_mae.values, palette='Reds')\n",
    "plt.title('Rata-rata MAE per Model')\n",
    "plt.ylabel('Rata-rata MAE')\n",
    "plt.xlabel('Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '7_avg_mae_per_model.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed2e69c",
   "metadata": {},
   "source": [
    "# Simpan hasil evaluasi model\n",
    "Semua grafik akan disimpan ke folder `results/all_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e31bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(results_dir, 'model_results_per_item_gridsearch.csv')\n",
    "all_results_sorted = sorted(all_results, key=lambda x: (x['item'], x['mae']))\n",
    "with open(csv_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Item', 'Model', 'Category', 'MAE', 'MSE', 'R2', 'Best_Params'])\n",
    "    for res in all_results_sorted:\n",
    "        writer.writerow([res['item'], res['model'], res['category'], res['mae'], res['mse'], res['r2'], res['best_params']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
