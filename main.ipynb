{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3444a841",
   "metadata": {},
   "source": [
    "# Prediksi Hasil Panen dengan Machine Learning & Deep Learning\n",
    "\n",
    "Notebook ini berisi seluruh kode dari `main.py` yang telah dibagi menjadi beberapa section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198eab96",
   "metadata": {},
   "source": [
    "# Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b97856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "rcParams[\"figure.figsize\"] = 15, 7\n",
    "sns.set(palette=\"Set2\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a7cb9",
   "metadata": {},
   "source": [
    "# Memuat dan Memeriksa Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da78672b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran awal dataset: (28242, 8)\n"
     ]
    }
   ],
   "source": [
    "pred_csv_path = \"dataset/yield_df.csv\"\n",
    "\n",
    "x = pd.read_csv(pred_csv_path)\n",
    "x.head()\n",
    "\n",
    "data = pd.read_csv(pred_csv_path)\n",
    "print(f\"Ukuran awal dataset: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046086b3",
   "metadata": {},
   "source": [
    "# Data Preprocessing dan Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d876ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, col):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    mask = (df[col] >= Q1 - 1.5 * IQR) & (df[col] <= Q3 + 1.5 * IQR)\n",
    "    return df[mask]\n",
    "\n",
    "features = ['avg_temp', 'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'rolling_yield_mean3']\n",
    "target = 'log_yield'\n",
    "look_back = 9\n",
    "\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefe7d7c",
   "metadata": {},
   "source": [
    "# Pembuatan urutan untuk Time Series Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc37550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences_all(data, features, target, look_back=9):\n",
    "    X, y = [], []\n",
    "    areas = data['Area'].unique()\n",
    "    for area in areas:\n",
    "        region_data = data[data['Area'] == area].sort_values('Year')\n",
    "        for i in range(look_back, len(region_data)):\n",
    "            X.append(region_data[features].iloc[i-look_back:i].values)\n",
    "            y.append(region_data[target].iloc[i])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e38955",
   "metadata": {},
   "source": [
    "# Inisialisasi kamus scaler untuk fitur dan target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174449c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa3006",
   "metadata": {},
   "source": [
    "# Membuat kolom log_yield, rolling_yield_mean3, dan scaling fitur/target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb89835",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_yield'] = np.log(data['hg/ha_yield'] + 1)\n",
    "data['rolling_yield_mean3'] = data.groupby('Area')['hg/ha_yield'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "\n",
    "scaler_rolling = MinMaxScaler()\n",
    "data['rolling_yield_mean3'] = scaler_rolling.fit_transform(data[['rolling_yield_mean3']])\n",
    "\n",
    "for col in features:\n",
    "    scaler = MinMaxScaler()\n",
    "    data[col] = scaler.fit_transform(data[[col]])\n",
    "    scaler_dict[col] = scaler\n",
    "\n",
    "target_scaler = MinMaxScaler()\n",
    "data[target] = target_scaler.fit_transform(data[[target]])\n",
    "scaler_dict[target] = target_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7392eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membuat sequence data untuk training dan testing...\n",
      "Jumlah data training: 19133\n",
      "Jumlah data testing: 8200\n",
      "Jumlah data training: 19133\n",
      "Jumlah data testing: 8200\n"
     ]
    }
   ],
   "source": [
    "print(\"Membuat sequence data untuk training dan testing...\")\n",
    "X, y = create_sequences_all(data, features, target, look_back=look_back)\n",
    "X_rf = X.reshape(X.shape[0], -1)  # Untuk model tree-based\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Jumlah data training: {X_train.shape[0]}\")\n",
    "print(f\"Jumlah data testing: {X_test.shape[0]}\")\n",
    "X_train_rf = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_rf = X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259f706c",
   "metadata": {},
   "source": [
    "# Inisiasi grid parameter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5564f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_param_grid = {\n",
    "    'model__units': [32, 64],\n",
    "    'model__dropout': [0.1, 0.2, 0.3],\n",
    "    'model__lr': [0.001, 0.0005],\n",
    "    'batch_size': [8, 16],\n",
    "    'epochs': [50],\n",
    "}\n",
    "lstm_param_grid = {\n",
    "    'model__units1': [32, 64],\n",
    "    'model__units2': [16, 32],\n",
    "    'model__dropout': [0.1, 0.2, 0.3],\n",
    "    'model__lr': [0.001, 0.0005],\n",
    "    'batch_size': [8, 16],\n",
    "    'epochs': [50],\n",
    "}\n",
    "gru_param_grid = {\n",
    "    'model__units1': [32, 64],\n",
    "    'model__units2': [16, 32],\n",
    "    'model__dropout': [0.1, 0.2, 0.3],\n",
    "    'model__lr': [0.001, 0.0005],\n",
    "    'batch_size': [8, 16],\n",
    "    'epochs': [50],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aab4483",
   "metadata": {},
   "source": [
    "## Train & Evaluasi SimpleRNN\n",
    "Training dan evaluasi model SimpleRNN pada data hasil split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9eab29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] GridSearchCV SimpleRNN...\n",
      "[INFO] SimpleRNN selesai training. Evaluasi...\n",
      "[INFO] Evaluasi SimpleRNN selesai.\n"
     ]
    }
   ],
   "source": [
    "def build_rnn_model(units=64, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        SimpleRNN(units, activation='tanh'),\n",
    "        Dropout(dropout),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "print(\"[INFO] GridSearchCV SimpleRNN...\")\n",
    "rnn_reg = KerasRegressor(model=build_rnn_model, verbose=0)\n",
    "rnn_grid = GridSearchCV(rnn_reg, rnn_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "rnn_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] SimpleRNN selesai training. Evaluasi...\")\n",
    "rnn_best = rnn_grid.best_estimator_\n",
    "y_pred = rnn_best.predict(X_test)\n",
    "y_pred = y_pred.reshape(-1, 1)\n",
    "y_pred = y_pred if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_pred)\n",
    "y_true = y_test.reshape(-1, 1)\n",
    "y_true = y_true if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_true)\n",
    "all_results.append({\n",
    "    'item': 'ALL',\n",
    "    'model': 'SimpleRNN',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rnn_grid.best_params_)\n",
    "})\n",
    "print(\"[INFO] Evaluasi SimpleRNN selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee0052",
   "metadata": {},
   "source": [
    "## Train & Evaluasi LSTM\n",
    "Training dan evaluasi model LSTM pada data hasil split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb187f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] GridSearchCV LSTM...\n"
     ]
    }
   ],
   "source": [
    "def build_lstm_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        LSTM(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        LSTM(units2, activation='tanh'),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "print(\"[INFO] GridSearchCV LSTM...\")\n",
    "lstm_reg = KerasRegressor(model=build_lstm_model, verbose=0)\n",
    "lstm_grid = GridSearchCV(lstm_reg, lstm_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "lstm_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] LSTM selesai training. Evaluasi...\")\n",
    "lstm_best = lstm_grid.best_estimator_\n",
    "y_pred = lstm_best.predict(X_test)\n",
    "y_pred = y_pred.reshape(-1, 1)\n",
    "y_pred = y_pred if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_pred)\n",
    "y_true = y_test.reshape(-1, 1)\n",
    "y_true = y_true if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_true)\n",
    "all_results.append({\n",
    "    'item': 'ALL',\n",
    "    'model': 'LSTM',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(lstm_grid.best_params_)\n",
    "})\n",
    "print(\"[INFO] Evaluasi LSTM selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dd57c2",
   "metadata": {},
   "source": [
    "## Train & Evaluasi GRU\n",
    "Training dan evaluasi model GRU pada data hasil split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85863f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gru_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        GRU(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        GRU(units2),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "print(\"[INFO] GridSearchCV GRU...\")\n",
    "gru_reg = KerasRegressor(model=build_gru_model, verbose=0)\n",
    "gru_grid = GridSearchCV(gru_reg, gru_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "gru_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] GRU selesai training. Evaluasi...\")\n",
    "gru_best = gru_grid.best_estimator_\n",
    "y_pred = gru_best.predict(X_test)\n",
    "y_pred = y_pred.reshape(-1, 1)\n",
    "y_pred = y_pred if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_pred)\n",
    "y_true = y_test.reshape(-1, 1)\n",
    "y_true = y_true if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_true)\n",
    "all_results.append({\n",
    "    'item': 'ALL',\n",
    "    'model': 'GRU',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gru_grid.best_params_)\n",
    "})\n",
    "print(\"[INFO] Evaluasi GRU selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54077207",
   "metadata": {},
   "source": [
    "## Train & Evaluasi RandomForest\n",
    "Training dan evaluasi model RandomForest pada data hasil split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV RandomForest...\")\n",
    "rf_grid = GridSearchCV(rf, rf_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] RandomForest selesai training. Evaluasi...\")\n",
    "rf_best = rf_grid.best_estimator_\n",
    "y_pred = rf_best.predict(X_test_rf)\n",
    "y_pred = y_pred.reshape(-1, 1)\n",
    "y_pred = y_pred if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_pred)\n",
    "y_true = y_test.reshape(-1, 1)\n",
    "y_true = y_true if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_true)\n",
    "all_results.append({\n",
    "    'item': 'ALL',\n",
    "    'model': 'RandomForest',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rf_grid.best_params_)\n",
    "})\n",
    "print(\"[INFO] Evaluasi RandomForest selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d63b33",
   "metadata": {},
   "source": [
    "## Train & Evaluasi BaggingRegressor\n",
    "Training dan evaluasi model BaggingRegressor pada data hasil split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c2fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_param_grid = {\n",
    "    'estimator': [RandomForestRegressor(max_depth=3), RandomForestRegressor(max_depth=5)],\n",
    "    'n_estimators': [10, 20, 50]\n",
    "}\n",
    "bag = BaggingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV BaggingRegressor...\")\n",
    "bag_grid = GridSearchCV(bag, bag_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] BaggingRegressor selesai training. Evaluasi...\")\n",
    "bag_best = bag_grid.best_estimator_\n",
    "y_pred = bag_best.predict(X_test_rf)\n",
    "y_pred = y_pred.reshape(-1, 1)\n",
    "y_pred = y_pred if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_pred)\n",
    "y_true = y_test.reshape(-1, 1)\n",
    "y_true = y_true if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_true)\n",
    "all_results.append({\n",
    "    'item': 'ALL',\n",
    "    'model': 'BaggingRegressor',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(bag_grid.best_params_)\n",
    "})\n",
    "print(\"[INFO] Evaluasi BaggingRegressor selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cf65b3",
   "metadata": {},
   "source": [
    "## Train & Evaluasi GradientBoosting\n",
    "Training dan evaluasi model GradientBoosting pada data hasil split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ffeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV GradientBoostingRegressor...\")\n",
    "gb_grid = GridSearchCV(gb, gb_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "gb_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] GradientBoostingRegressor selesai training. Evaluasi...\")\n",
    "gb_best = gb_grid.best_estimator_\n",
    "y_pred = gb_best.predict(X_test_rf)\n",
    "y_pred = y_pred.reshape(-1, 1)\n",
    "y_pred = y_pred if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_pred)\n",
    "y_true = y_test.reshape(-1, 1)\n",
    "y_true = y_true if not hasattr(scaler_dict[target], 'inverse_transform') else scaler_dict[target].inverse_transform(y_true)\n",
    "all_results.append({\n",
    "    'item': 'ALL',\n",
    "    'model': 'GradientBoosting',\n",
    "    'category': 'Boosting',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gb_grid.best_params_)\n",
    "})\n",
    "print(\"[INFO] Evaluasi GradientBoostingRegressor selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1440bb9f",
   "metadata": {},
   "source": [
    "# Visualisasi Hasil Evaluasi Model\n",
    "Bagian ini menampilkan berbagai visualisasi hasil evaluasi model, seperti distribusi yield, heatmap korelasi, boxplot, dan perbandingan performa model (R2 dan MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7aefb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results/all_models'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# 1. Histogram Yield\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(data['hg/ha_yield'], bins=30, kde=True, color='skyblue')\n",
    "plt.title('Distribusi Yield (hg/ha_yield)')\n",
    "plt.xlabel('Yield (hg/ha)')\n",
    "plt.ylabel('Frekuensi')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '1_hist_yield_distribution.png'))\n",
    "plt.close()\n",
    "\n",
    "# 2. Korelasi Heatmap\n",
    "plt.figure(figsize=(10,8))\n",
    "num_cols = data.select_dtypes(include='number').columns\n",
    "corr = data[num_cols].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', square=True)\n",
    "plt.title('Heatmap Korelasi Fitur Numerik')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '2_heatmap_korelasi.png'))\n",
    "plt.close()\n",
    "\n",
    "# 3. Jumlah Data per Area (Encoded)\n",
    "plt.figure(figsize=(14,6))\n",
    "area_counts = data['Area'].value_counts().sort_values(ascending=False)\n",
    "sns.barplot(x=area_counts.index, y=area_counts.values, palette='viridis')\n",
    "plt.title('Jumlah Data per Area')\n",
    "plt.xlabel('Area (Encoded)')\n",
    "plt.ylabel('Jumlah Data')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '3_countplot_area.png'))\n",
    "plt.close()\n",
    "\n",
    "# 4. Boxplot Yield per Crop\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x='Item', y='hg/ha_yield', data=data, palette='Set2')\n",
    "plt.title('Boxplot Yield per Crop')\n",
    "plt.xlabel('Crop (Item)')\n",
    "plt.ylabel('Yield (hg/ha)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '4_boxplot_yield_per_crop.png'))\n",
    "plt.close()\n",
    "\n",
    "# 5. R² Score Tiap Model per Crop\n",
    "df_results = pd.DataFrame(all_results)\n",
    "plt.figure(figsize=(14,7))\n",
    "sns.barplot(data=df_results, x='item', y='r2', hue='model', ci=None)\n",
    "plt.title('R² Score Tiap Model per Crop')\n",
    "plt.ylabel('R² Score')\n",
    "plt.xlabel('Crop (Item)')\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '5_r2score_per_model_crop.png'))\n",
    "plt.close()\n",
    "\n",
    "# 6. Rata-rata R² Score per Model\n",
    "plt.figure(figsize=(10,6))\n",
    "avg_r2 = df_results.groupby('model')['r2'].mean().sort_values(ascending=False)\n",
    "sns.barplot(x=avg_r2.index, y=avg_r2.values, palette='Blues_d')\n",
    "plt.title('Rata-rata R² Score per Model')\n",
    "plt.ylabel('Rata-rata R²')\n",
    "plt.xlabel('Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '6_avg_r2_score_per_model.png'))\n",
    "plt.close()\n",
    "\n",
    "# 7. Rata-rata MAE per Model\n",
    "plt.figure(figsize=(10,6))\n",
    "avg_mae = df_results.groupby('model')['mae'].mean().sort_values()\n",
    "sns.barplot(x=avg_mae.index, y=avg_mae.values, palette='Reds')\n",
    "plt.title('Rata-rata MAE per Model')\n",
    "plt.ylabel('Rata-rata MAE')\n",
    "plt.xlabel('Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '7_avg_mae_per_model.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed2e69c",
   "metadata": {},
   "source": [
    "# Simpan hasil evaluasi model\n",
    "Semua grafik akan disimpan ke folder `results/all_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e31bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(results_dir, 'model_results_per_item_gridsearch.csv')\n",
    "all_results_sorted = sorted(all_results, key=lambda x: (x['item'], x['mae']))\n",
    "with open(csv_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Item', 'Model', 'Category', 'MAE', 'MSE', 'R2', 'Best_Params'])\n",
    "    for res in all_results_sorted:\n",
    "        writer.writerow([res['item'], res['model'], res['category'], res['mae'], res['mse'], res['r2'], res['best_params']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
