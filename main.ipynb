{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1691c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный размер датасета: (28242, 8)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "rcParams[\"figure.figsize\"] = 15, 7\n",
    "sns.set(palette=\"Set2\", font_scale=1.2)\n",
    "\n",
    "pred_csv_path = \"dataset/yield_df.csv\"\n",
    "\n",
    "x = pd.read_csv(pred_csv_path)\n",
    "x.head()\n",
    "\n",
    "data = pd.read_csv(pred_csv_path)\n",
    "print(f\"Исходный размер датасета: {data.shape}\")\n",
    "\n",
    "def remove_outliers(df, col):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    mask = (df[col] >= Q1 - 1.5 * IQR) & (df[col] <= Q3 + 1.5 * IQR)\n",
    "    return df[mask]\n",
    "\n",
    "features = ['avg_temp', 'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'rolling_yield_mean3']\n",
    "target = 'log_yield'\n",
    "look_back = 9\n",
    "\n",
    "all_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6830679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_param_grid = {\n",
    "    'model__units': [32, 64],\n",
    "    'model__dropout': [0.1, 0.2, 0.3],\n",
    "    'model__lr': [0.001, 0.0005],\n",
    "    'batch_size': [8, 16],\n",
    "    'epochs': [50],\n",
    "}\n",
    "lstm_param_grid = {\n",
    "    'model__units1': [32, 64],\n",
    "    'model__units2': [16, 32],\n",
    "    'model__dropout': [0.1, 0.2, 0.3],\n",
    "    'model__lr': [0.001, 0.0005],\n",
    "    'batch_size': [8, 16],\n",
    "    'epochs': [50],\n",
    "}\n",
    "gru_param_grid = {\n",
    "    'model__units1': [32, 64],\n",
    "    'model__units2': [16, 32],\n",
    "    'model__dropout': [0.1, 0.2, 0.3],\n",
    "    'model__lr': [0.001, 0.0005],\n",
    "    'batch_size': [8, 16],\n",
    "    'epochs': [50],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23602c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mulai proses untuk crop: Cassava ===\n",
      "Membuat sequence data untuk training dan testing...\n",
      "Jumlah data training: 1173\n",
      "Jumlah data testing: 503\n",
      "[INFO] Mulai training SimpleRNN...\n",
      "[INFO] GridSearchCV SimpleRNN...\n",
      "[INFO] SimpleRNN selesai training. Evaluasi...\n",
      "[INFO] Evaluasi SimpleRNN selesai.\n",
      "MAE: 0.1166020575462913, MSE: 0.028291036698565312, R²: 0.9388951356527148\n",
      "[INFO] Mulai training LSTM...\n",
      "[INFO] GridSearchCV LSTM...\n"
     ]
    }
   ],
   "source": [
    "item = \"Cassava\"\n",
    "print(f\"\\n=== Mulai proses untuk crop: {item} ===\")\n",
    "\n",
    "crop_data = data[data['Item'] == item].dropna().sort_values(['Area', 'Year'])\n",
    "crop_data = remove_outliers(crop_data, 'hg/ha_yield')\n",
    "crop_data['log_yield'] = np.log(crop_data['hg/ha_yield'] + 1)\n",
    "crop_data['rolling_yield_mean3'] = crop_data.groupby('Area')['hg/ha_yield'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "scaler_rolling = MinMaxScaler()\n",
    "crop_data['rolling_yield_mean3'] = scaler_rolling.fit_transform(crop_data[['rolling_yield_mean3']])\n",
    "scaler_dict = {}\n",
    "for col in features:\n",
    "    scaler = MinMaxScaler()\n",
    "    crop_data[col] = scaler.fit_transform(crop_data[[col]])\n",
    "    scaler_dict[col] = scaler\n",
    "target_scaler = MinMaxScaler()\n",
    "crop_data[target] = target_scaler.fit_transform(crop_data[[target]])\n",
    "scaler_dict[target] = target_scaler\n",
    "\n",
    "def create_sequences_all(data, features, target, look_back=9):\n",
    "    X, y = [], []\n",
    "    areas = data['Area'].unique()\n",
    "    for area in areas:\n",
    "        region_data = data[data['Area'] == area].sort_values('Year')\n",
    "        for i in range(look_back, len(region_data)):\n",
    "            X.append(region_data[features].iloc[i-look_back:i].values)\n",
    "            y.append(region_data[target].iloc[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(\"Membuat sequence data untuk training dan testing...\")\n",
    "X, y = create_sequences_all(crop_data, features, target, look_back=look_back)\n",
    "X_rf = X.reshape(X.shape[0], -1)\n",
    "# Split for all models: 70% train, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Jumlah data training: {X_train.shape[0]}\")\n",
    "print(f\"Jumlah data testing: {X_test.shape[0]}\")\n",
    "X_train_rf = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_rf = X_test.reshape(X_test.shape[0], -1)\n",
    "predictions = {}\n",
    "\n",
    "# Model Definitions\n",
    "print(\"[INFO] Mulai training SimpleRNN...\")\n",
    "def build_rnn_model(units=64, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        SimpleRNN(units, activation='tanh'),\n",
    "        Dropout(dropout),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV SimpleRNN...\")\n",
    "rnn_reg = KerasRegressor(model=build_rnn_model, verbose=0)\n",
    "rnn_grid = GridSearchCV(rnn_reg, rnn_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "rnn_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] SimpleRNN selesai training. Evaluasi...\")\n",
    "rnn_best = rnn_grid.best_estimator_\n",
    "y_pred = rnn_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'SimpleRNN',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rnn_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi SimpleRNN selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training LSTM...\")\n",
    "def build_lstm_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        LSTM(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        LSTM(units2, activation='tanh'),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV LSTM...\")\n",
    "lstm_reg = KerasRegressor(model=build_lstm_model, verbose=0)\n",
    "lstm_grid = GridSearchCV(lstm_reg, lstm_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "lstm_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] LSTM selesai training. Evaluasi...\")\n",
    "lstm_best = lstm_grid.best_estimator_\n",
    "y_pred = lstm_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'LSTM',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(lstm_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi LSTM selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GRU...\")\n",
    "def build_gru_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        GRU(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        GRU(units2),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV GRU...\")\n",
    "gru_reg = KerasRegressor(model=build_gru_model, verbose=0)\n",
    "gru_grid = GridSearchCV(gru_reg, gru_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "gru_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] GRU selesai training. Evaluasi...\")\n",
    "gru_best = gru_grid.best_estimator_\n",
    "y_pred = gru_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GRU',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gru_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GRU selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training RandomForest...\")\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV RandomForest...\")\n",
    "rf_grid = GridSearchCV(rf, rf_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] RandomForest selesai training. Evaluasi...\")\n",
    "rf_best = rf_grid.best_estimator_\n",
    "y_pred = rf_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'RandomForest',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rf_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi RandomForest selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training BaggingRegressor...\")\n",
    "bag_param_grid = {\n",
    "    'estimator': [RandomForestRegressor(max_depth=3), RandomForestRegressor(max_depth=5)],\n",
    "    'n_estimators': [10, 20, 50]\n",
    "}\n",
    "bag = BaggingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV BaggingRegressor...\")\n",
    "bag_grid = GridSearchCV(bag, bag_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] BaggingRegressor selesai training. Evaluasi...\")\n",
    "bag_best = bag_grid.best_estimator_\n",
    "y_pred = bag_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'BaggingRegressor',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(bag_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi BaggingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GradientBoostingRegressor...\")\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV GradientBoostingRegressor...\")\n",
    "gb_grid = GridSearchCV(gb, gb_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "gb_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] GradientBoostingRegressor selesai training. Evaluasi...\")\n",
    "gb_best = gb_grid.best_estimator_\n",
    "y_pred = gb_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GradientBoosting',\n",
    "    'category': 'Boosting',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gb_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GradientBoostingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a91276c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mulai proses untuk crop: Maize ===\n",
      "Membuat sequence data untuk training dan testing...\n",
      "Jumlah data training: 2188\n",
      "Jumlah data testing: 939\n",
      "[INFO] Mulai training SimpleRNN...\n",
      "[INFO] GridSearchCV SimpleRNN...\n",
      "[INFO] SimpleRNN selesai training. Evaluasi...\n",
      "[INFO] Evaluasi SimpleRNN selesai.\n",
      "MAE: 0.1374737951115006, MSE: 0.04866085525632954, R²: 0.8845289075584111\n",
      "[INFO] Mulai training LSTM...\n",
      "[INFO] GridSearchCV LSTM...\n",
      "[INFO] LSTM selesai training. Evaluasi...\n",
      "[INFO] Evaluasi LSTM selesai.\n",
      "MAE: 0.09996620080107665, MSE: 0.030857639109203933, R²: 0.9267755307764634\n",
      "[INFO] Mulai training GRU...\n",
      "[INFO] GridSearchCV GRU...\n",
      "[INFO] GRU selesai training. Evaluasi...\n",
      "[INFO] Evaluasi GRU selesai.\n",
      "MAE: 0.09189325648302177, MSE: 0.030277726589259472, R²: 0.9281516498735446\n",
      "[INFO] Mulai training RandomForest...\n",
      "[INFO] GridSearchCV RandomForest...\n",
      "[INFO] RandomForest selesai training. Evaluasi...\n",
      "[INFO] Evaluasi RandomForest selesai.\n",
      "MAE: 0.07598510558509594, MSE: 0.02721454814492289, R²: 0.9354205020021775\n",
      "[INFO] Mulai training BaggingRegressor...\n",
      "[INFO] GridSearchCV BaggingRegressor...\n",
      "[INFO] BaggingRegressor selesai training. Evaluasi...\n",
      "[INFO] Evaluasi BaggingRegressor selesai.\n",
      "MAE: 0.08023693397619178, MSE: 0.02695228554070224, R²: 0.9360428451413684\n",
      "[INFO] Mulai training GradientBoostingRegressor...\n",
      "[INFO] GridSearchCV GradientBoostingRegressor...\n",
      "[INFO] GradientBoostingRegressor selesai training. Evaluasi...\n",
      "[INFO] Evaluasi GradientBoostingRegressor selesai.\n",
      "MAE: 0.08016651114174438, MSE: 0.029220284154364517, R²: 0.9306609364964\n"
     ]
    }
   ],
   "source": [
    "item = \"Maize\"\n",
    "print(f\"\\n=== Mulai proses untuk crop: {item} ===\")\n",
    "\n",
    "crop_data = data[data['Item'] == item].dropna().sort_values(['Area', 'Year'])\n",
    "crop_data = remove_outliers(crop_data, 'hg/ha_yield')\n",
    "crop_data['log_yield'] = np.log(crop_data['hg/ha_yield'] + 1)\n",
    "crop_data['rolling_yield_mean3'] = crop_data.groupby('Area')['hg/ha_yield'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "scaler_rolling = MinMaxScaler()\n",
    "crop_data['rolling_yield_mean3'] = scaler_rolling.fit_transform(crop_data[['rolling_yield_mean3']])\n",
    "scaler_dict = {}\n",
    "for col in features:\n",
    "    scaler = MinMaxScaler()\n",
    "    crop_data[col] = scaler.fit_transform(crop_data[[col]])\n",
    "    scaler_dict[col] = scaler\n",
    "target_scaler = MinMaxScaler()\n",
    "crop_data[target] = target_scaler.fit_transform(crop_data[[target]])\n",
    "scaler_dict[target] = target_scaler\n",
    "\n",
    "def create_sequences_all(data, features, target, look_back=9):\n",
    "    X, y = [], []\n",
    "    areas = data['Area'].unique()\n",
    "    for area in areas:\n",
    "        region_data = data[data['Area'] == area].sort_values('Year')\n",
    "        for i in range(look_back, len(region_data)):\n",
    "            X.append(region_data[features].iloc[i-look_back:i].values)\n",
    "            y.append(region_data[target].iloc[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(\"Membuat sequence data untuk training dan testing...\")\n",
    "X, y = create_sequences_all(crop_data, features, target, look_back=look_back)\n",
    "X_rf = X.reshape(X.shape[0], -1)\n",
    "# Split for all models: 70% train, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Jumlah data training: {X_train.shape[0]}\")\n",
    "print(f\"Jumlah data testing: {X_test.shape[0]}\")\n",
    "X_train_rf = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_rf = X_test.reshape(X_test.shape[0], -1)\n",
    "predictions = {}\n",
    "\n",
    "# Model Definitions\n",
    "print(\"[INFO] Mulai training SimpleRNN...\")\n",
    "def build_rnn_model(units=64, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        SimpleRNN(units, activation='tanh'),\n",
    "        Dropout(dropout),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV SimpleRNN...\")\n",
    "rnn_reg = KerasRegressor(model=build_rnn_model, verbose=0)\n",
    "rnn_grid = GridSearchCV(rnn_reg, rnn_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "rnn_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] SimpleRNN selesai training. Evaluasi...\")\n",
    "rnn_best = rnn_grid.best_estimator_\n",
    "y_pred = rnn_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'SimpleRNN',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rnn_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi SimpleRNN selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training LSTM...\")\n",
    "def build_lstm_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        LSTM(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        LSTM(units2, activation='tanh'),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV LSTM...\")\n",
    "lstm_reg = KerasRegressor(model=build_lstm_model, verbose=0)\n",
    "lstm_grid = GridSearchCV(lstm_reg, lstm_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "lstm_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] LSTM selesai training. Evaluasi...\")\n",
    "lstm_best = lstm_grid.best_estimator_\n",
    "y_pred = lstm_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'LSTM',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(lstm_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi LSTM selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GRU...\")\n",
    "def build_gru_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        GRU(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        GRU(units2),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV GRU...\")\n",
    "gru_reg = KerasRegressor(model=build_gru_model, verbose=0)\n",
    "gru_grid = GridSearchCV(gru_reg, gru_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "gru_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] GRU selesai training. Evaluasi...\")\n",
    "gru_best = gru_grid.best_estimator_\n",
    "y_pred = gru_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GRU',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gru_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GRU selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training RandomForest...\")\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV RandomForest...\")\n",
    "rf_grid = GridSearchCV(rf, rf_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] RandomForest selesai training. Evaluasi...\")\n",
    "rf_best = rf_grid.best_estimator_\n",
    "y_pred = rf_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'RandomForest',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rf_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi RandomForest selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training BaggingRegressor...\")\n",
    "bag_param_grid = {\n",
    "    'estimator': [RandomForestRegressor(max_depth=3), RandomForestRegressor(max_depth=5)],\n",
    "    'n_estimators': [10, 20, 50]\n",
    "}\n",
    "bag = BaggingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV BaggingRegressor...\")\n",
    "bag_grid = GridSearchCV(bag, bag_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] BaggingRegressor selesai training. Evaluasi...\")\n",
    "bag_best = bag_grid.best_estimator_\n",
    "y_pred = bag_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'BaggingRegressor',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(bag_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi BaggingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GradientBoostingRegressor...\")\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV GradientBoostingRegressor...\")\n",
    "gb_grid = GridSearchCV(gb, gb_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "gb_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] GradientBoostingRegressor selesai training. Evaluasi...\")\n",
    "gb_best = gb_grid.best_estimator_\n",
    "y_pred = gb_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GradientBoosting',\n",
    "    'category': 'Boosting',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gb_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GradientBoostingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4f48017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mulai proses untuk crop: Plantains and others ===\n",
      "Membuat sequence data untuk training dan testing...\n",
      "Jumlah data training: 233\n",
      "Jumlah data testing: 101\n",
      "[INFO] Mulai training SimpleRNN...\n",
      "[INFO] GridSearchCV SimpleRNN...\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x85689f600> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x85689f600> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[INFO] SimpleRNN selesai training. Evaluasi...\n",
      "[INFO] Evaluasi SimpleRNN selesai.\n",
      "MAE: 0.09747961959444915, MSE: 0.019585554070884924, R²: 0.8897881832861592\n",
      "[INFO] Mulai training LSTM...\n",
      "[INFO] GridSearchCV LSTM...\n",
      "[INFO] LSTM selesai training. Evaluasi...\n",
      "[INFO] Evaluasi LSTM selesai.\n",
      "MAE: 0.12013714379735187, MSE: 0.026091634072135127, R²: 0.8531771742726687\n",
      "[INFO] Mulai training GRU...\n",
      "[INFO] GridSearchCV GRU...\n",
      "[INFO] GRU selesai training. Evaluasi...\n",
      "[INFO] Evaluasi GRU selesai.\n",
      "MAE: 0.14145990081477838, MSE: 0.033475893376444334, R²: 0.8116244752747981\n",
      "[INFO] Mulai training RandomForest...\n",
      "[INFO] GridSearchCV RandomForest...\n",
      "[INFO] RandomForest selesai training. Evaluasi...\n",
      "[INFO] Evaluasi RandomForest selesai.\n",
      "MAE: 0.08228209965919735, MSE: 0.022349329657734222, R²: 0.8742358671600186\n",
      "[INFO] Mulai training BaggingRegressor...\n",
      "[INFO] GridSearchCV BaggingRegressor...\n",
      "[INFO] BaggingRegressor selesai training. Evaluasi...\n",
      "[INFO] Evaluasi BaggingRegressor selesai.\n",
      "MAE: 0.07700158960143887, MSE: 0.018490374135026088, R²: 0.8959509790856909\n",
      "[INFO] Mulai training GradientBoostingRegressor...\n",
      "[INFO] GridSearchCV GradientBoostingRegressor...\n",
      "[INFO] GradientBoostingRegressor selesai training. Evaluasi...\n",
      "[INFO] Evaluasi GradientBoostingRegressor selesai.\n",
      "MAE: 0.07671138168934187, MSE: 0.02029241876946611, R²: 0.8858105147290402\n"
     ]
    }
   ],
   "source": [
    "item = \"Plantains and others\"\n",
    "print(f\"\\n=== Mulai proses untuk crop: {item} ===\")\n",
    "\n",
    "crop_data = data[data['Item'] == item].dropna().sort_values(['Area', 'Year'])\n",
    "crop_data = remove_outliers(crop_data, 'hg/ha_yield')\n",
    "crop_data['log_yield'] = np.log(crop_data['hg/ha_yield'] + 1)\n",
    "crop_data['rolling_yield_mean3'] = crop_data.groupby('Area')['hg/ha_yield'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "scaler_rolling = MinMaxScaler()\n",
    "crop_data['rolling_yield_mean3'] = scaler_rolling.fit_transform(crop_data[['rolling_yield_mean3']])\n",
    "scaler_dict = {}\n",
    "for col in features:\n",
    "    scaler = MinMaxScaler()\n",
    "    crop_data[col] = scaler.fit_transform(crop_data[[col]])\n",
    "    scaler_dict[col] = scaler\n",
    "target_scaler = MinMaxScaler()\n",
    "crop_data[target] = target_scaler.fit_transform(crop_data[[target]])\n",
    "scaler_dict[target] = target_scaler\n",
    "\n",
    "def create_sequences_all(data, features, target, look_back=9):\n",
    "    X, y = [], []\n",
    "    areas = data['Area'].unique()\n",
    "    for area in areas:\n",
    "        region_data = data[data['Area'] == area].sort_values('Year')\n",
    "        for i in range(look_back, len(region_data)):\n",
    "            X.append(region_data[features].iloc[i-look_back:i].values)\n",
    "            y.append(region_data[target].iloc[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(\"Membuat sequence data untuk training dan testing...\")\n",
    "X, y = create_sequences_all(crop_data, features, target, look_back=look_back)\n",
    "X_rf = X.reshape(X.shape[0], -1)\n",
    "# Split for all models: 70% train, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Jumlah data training: {X_train.shape[0]}\")\n",
    "print(f\"Jumlah data testing: {X_test.shape[0]}\")\n",
    "X_train_rf = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_rf = X_test.reshape(X_test.shape[0], -1)\n",
    "predictions = {}\n",
    "\n",
    "# Model Definitions\n",
    "print(\"[INFO] Mulai training SimpleRNN...\")\n",
    "def build_rnn_model(units=64, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        SimpleRNN(units, activation='tanh'),\n",
    "        Dropout(dropout),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV SimpleRNN...\")\n",
    "rnn_reg = KerasRegressor(model=build_rnn_model, verbose=0)\n",
    "rnn_grid = GridSearchCV(rnn_reg, rnn_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "rnn_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] SimpleRNN selesai training. Evaluasi...\")\n",
    "rnn_best = rnn_grid.best_estimator_\n",
    "y_pred = rnn_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'SimpleRNN',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rnn_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi SimpleRNN selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training LSTM...\")\n",
    "def build_lstm_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        LSTM(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        LSTM(units2, activation='tanh'),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV LSTM...\")\n",
    "lstm_reg = KerasRegressor(model=build_lstm_model, verbose=0)\n",
    "lstm_grid = GridSearchCV(lstm_reg, lstm_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "lstm_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] LSTM selesai training. Evaluasi...\")\n",
    "lstm_best = lstm_grid.best_estimator_\n",
    "y_pred = lstm_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'LSTM',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(lstm_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi LSTM selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GRU...\")\n",
    "def build_gru_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        GRU(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        GRU(units2),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV GRU...\")\n",
    "gru_reg = KerasRegressor(model=build_gru_model, verbose=0)\n",
    "gru_grid = GridSearchCV(gru_reg, gru_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "gru_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] GRU selesai training. Evaluasi...\")\n",
    "gru_best = gru_grid.best_estimator_\n",
    "y_pred = gru_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GRU',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gru_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GRU selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training RandomForest...\")\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV RandomForest...\")\n",
    "rf_grid = GridSearchCV(rf, rf_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] RandomForest selesai training. Evaluasi...\")\n",
    "rf_best = rf_grid.best_estimator_\n",
    "y_pred = rf_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'RandomForest',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rf_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi RandomForest selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training BaggingRegressor...\")\n",
    "bag_param_grid = {\n",
    "    'estimator': [RandomForestRegressor(max_depth=3), RandomForestRegressor(max_depth=5)],\n",
    "    'n_estimators': [10, 20, 50]\n",
    "}\n",
    "bag = BaggingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV BaggingRegressor...\")\n",
    "bag_grid = GridSearchCV(bag, bag_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] BaggingRegressor selesai training. Evaluasi...\")\n",
    "bag_best = bag_grid.best_estimator_\n",
    "y_pred = bag_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'BaggingRegressor',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(bag_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi BaggingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GradientBoostingRegressor...\")\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV GradientBoostingRegressor...\")\n",
    "gb_grid = GridSearchCV(gb, gb_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "gb_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] GradientBoostingRegressor selesai training. Evaluasi...\")\n",
    "gb_best = gb_grid.best_estimator_\n",
    "y_pred = gb_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GradientBoosting',\n",
    "    'category': 'Boosting',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gb_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GradientBoostingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c03af94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mulai proses untuk crop: Potatoes ===\n",
      "Membuat sequence data untuk training dan testing...\n",
      "Jumlah data training: 2325\n",
      "Jumlah data testing: 997\n",
      "[INFO] Mulai training SimpleRNN...\n",
      "[INFO] GridSearchCV SimpleRNN...\n",
      "[INFO] SimpleRNN selesai training. Evaluasi...\n",
      "[INFO] Evaluasi SimpleRNN selesai.\n",
      "MAE: 0.07826009725117195, MSE: 0.019582962657591244, R²: 0.9273084300679113\n",
      "[INFO] Mulai training LSTM...\n",
      "[INFO] GridSearchCV LSTM...\n",
      "[INFO] LSTM selesai training. Evaluasi...\n",
      "[INFO] Evaluasi LSTM selesai.\n",
      "MAE: 0.07323112232716264, MSE: 0.017465677832057533, R²: 0.9351677494493825\n",
      "[INFO] Mulai training GRU...\n",
      "[INFO] GridSearchCV GRU...\n",
      "[INFO] GRU selesai training. Evaluasi...\n",
      "[INFO] Evaluasi GRU selesai.\n",
      "MAE: 0.1276187735518404, MSE: 0.02632786138527012, R²: 0.9022714994399573\n",
      "[INFO] Mulai training RandomForest...\n",
      "[INFO] GridSearchCV RandomForest...\n",
      "[INFO] RandomForest selesai training. Evaluasi...\n",
      "[INFO] Evaluasi RandomForest selesai.\n",
      "MAE: 0.05414595167241787, MSE: 0.014569819635347248, R²: 0.945917117780429\n",
      "[INFO] Mulai training BaggingRegressor...\n",
      "[INFO] GridSearchCV BaggingRegressor...\n",
      "[INFO] BaggingRegressor selesai training. Evaluasi...\n",
      "[INFO] Evaluasi BaggingRegressor selesai.\n",
      "MAE: 0.057404798723313104, MSE: 0.013886150540431368, R²: 0.948454883934225\n",
      "[INFO] Mulai training GradientBoostingRegressor...\n",
      "[INFO] GridSearchCV GradientBoostingRegressor...\n",
      "[INFO] GradientBoostingRegressor selesai training. Evaluasi...\n",
      "[INFO] Evaluasi GradientBoostingRegressor selesai.\n",
      "MAE: 0.05400073751782144, MSE: 0.012968218284960293, R²: 0.9518622303050577\n"
     ]
    }
   ],
   "source": [
    "item = \"Potatoes\"\n",
    "print(f\"\\n=== Mulai proses untuk crop: {item} ===\")\n",
    "\n",
    "crop_data = data[data['Item'] == item].dropna().sort_values(['Area', 'Year'])\n",
    "crop_data = remove_outliers(crop_data, 'hg/ha_yield')\n",
    "crop_data['log_yield'] = np.log(crop_data['hg/ha_yield'] + 1)\n",
    "crop_data['rolling_yield_mean3'] = crop_data.groupby('Area')['hg/ha_yield'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "scaler_rolling = MinMaxScaler()\n",
    "crop_data['rolling_yield_mean3'] = scaler_rolling.fit_transform(crop_data[['rolling_yield_mean3']])\n",
    "scaler_dict = {}\n",
    "for col in features:\n",
    "    scaler = MinMaxScaler()\n",
    "    crop_data[col] = scaler.fit_transform(crop_data[[col]])\n",
    "    scaler_dict[col] = scaler\n",
    "target_scaler = MinMaxScaler()\n",
    "crop_data[target] = target_scaler.fit_transform(crop_data[[target]])\n",
    "scaler_dict[target] = target_scaler\n",
    "\n",
    "def create_sequences_all(data, features, target, look_back=9):\n",
    "    X, y = [], []\n",
    "    areas = data['Area'].unique()\n",
    "    for area in areas:\n",
    "        region_data = data[data['Area'] == area].sort_values('Year')\n",
    "        for i in range(look_back, len(region_data)):\n",
    "            X.append(region_data[features].iloc[i-look_back:i].values)\n",
    "            y.append(region_data[target].iloc[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(\"Membuat sequence data untuk training dan testing...\")\n",
    "X, y = create_sequences_all(crop_data, features, target, look_back=look_back)\n",
    "X_rf = X.reshape(X.shape[0], -1)\n",
    "# Split for all models: 70% train, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Jumlah data training: {X_train.shape[0]}\")\n",
    "print(f\"Jumlah data testing: {X_test.shape[0]}\")\n",
    "X_train_rf = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_rf = X_test.reshape(X_test.shape[0], -1)\n",
    "predictions = {}\n",
    "\n",
    "# Model Definitions\n",
    "print(\"[INFO] Mulai training SimpleRNN...\")\n",
    "def build_rnn_model(units=64, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        SimpleRNN(units, activation='tanh'),\n",
    "        Dropout(dropout),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV SimpleRNN...\")\n",
    "rnn_reg = KerasRegressor(model=build_rnn_model, verbose=0)\n",
    "rnn_grid = GridSearchCV(rnn_reg, rnn_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "rnn_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] SimpleRNN selesai training. Evaluasi...\")\n",
    "rnn_best = rnn_grid.best_estimator_\n",
    "y_pred = rnn_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'SimpleRNN',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rnn_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi SimpleRNN selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training LSTM...\")\n",
    "def build_lstm_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        LSTM(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        LSTM(units2, activation='tanh'),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV LSTM...\")\n",
    "lstm_reg = KerasRegressor(model=build_lstm_model, verbose=0)\n",
    "lstm_grid = GridSearchCV(lstm_reg, lstm_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "lstm_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] LSTM selesai training. Evaluasi...\")\n",
    "lstm_best = lstm_grid.best_estimator_\n",
    "y_pred = lstm_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'LSTM',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(lstm_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi LSTM selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GRU...\")\n",
    "def build_gru_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        GRU(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        GRU(units2),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV GRU...\")\n",
    "gru_reg = KerasRegressor(model=build_gru_model, verbose=0)\n",
    "gru_grid = GridSearchCV(gru_reg, gru_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "gru_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] GRU selesai training. Evaluasi...\")\n",
    "gru_best = gru_grid.best_estimator_\n",
    "y_pred = gru_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GRU',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gru_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GRU selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training RandomForest...\")\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV RandomForest...\")\n",
    "rf_grid = GridSearchCV(rf, rf_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] RandomForest selesai training. Evaluasi...\")\n",
    "rf_best = rf_grid.best_estimator_\n",
    "y_pred = rf_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'RandomForest',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rf_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi RandomForest selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training BaggingRegressor...\")\n",
    "bag_param_grid = {\n",
    "    'estimator': [RandomForestRegressor(max_depth=3), RandomForestRegressor(max_depth=5)],\n",
    "    'n_estimators': [10, 20, 50]\n",
    "}\n",
    "bag = BaggingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV BaggingRegressor...\")\n",
    "bag_grid = GridSearchCV(bag, bag_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] BaggingRegressor selesai training. Evaluasi...\")\n",
    "bag_best = bag_grid.best_estimator_\n",
    "y_pred = bag_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'BaggingRegressor',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(bag_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi BaggingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GradientBoostingRegressor...\")\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV GradientBoostingRegressor...\")\n",
    "gb_grid = GridSearchCV(gb, gb_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "gb_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] GradientBoostingRegressor selesai training. Evaluasi...\")\n",
    "gb_best = gb_grid.best_estimator_\n",
    "y_pred = gb_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GradientBoosting',\n",
    "    'category': 'Boosting',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gb_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GradientBoostingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56a27684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mulai proses untuk crop: Rice, paddy ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m item = \u001b[33m\"\u001b[39m\u001b[33mRice, paddy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Mulai proses untuk crop: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m crop_data = \u001b[43mdata\u001b[49m[data[\u001b[33m'\u001b[39m\u001b[33mItem\u001b[39m\u001b[33m'\u001b[39m] == item].dropna().sort_values([\u001b[33m'\u001b[39m\u001b[33mArea\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mYear\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      5\u001b[39m crop_data = remove_outliers(crop_data, \u001b[33m'\u001b[39m\u001b[33mhg/ha_yield\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m crop_data[\u001b[33m'\u001b[39m\u001b[33mlog_yield\u001b[39m\u001b[33m'\u001b[39m] = np.log(crop_data[\u001b[33m'\u001b[39m\u001b[33mhg/ha_yield\u001b[39m\u001b[33m'\u001b[39m] + \u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "item = \"Rice, paddy\"\n",
    "print(f\"\\n=== Mulai proses untuk crop: {item} ===\")\n",
    "\n",
    "crop_data = data[data['Item'] == item].dropna().sort_values(['Area', 'Year'])\n",
    "crop_data = remove_outliers(crop_data, 'hg/ha_yield')\n",
    "crop_data['log_yield'] = np.log(crop_data['hg/ha_yield'] + 1)\n",
    "crop_data['rolling_yield_mean3'] = crop_data.groupby('Area')['hg/ha_yield'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "scaler_rolling = MinMaxScaler()\n",
    "crop_data['rolling_yield_mean3'] = scaler_rolling.fit_transform(crop_data[['rolling_yield_mean3']])\n",
    "scaler_dict = {}\n",
    "for col in features:\n",
    "    scaler = MinMaxScaler()\n",
    "    crop_data[col] = scaler.fit_transform(crop_data[[col]])\n",
    "    scaler_dict[col] = scaler\n",
    "target_scaler = MinMaxScaler()\n",
    "crop_data[target] = target_scaler.fit_transform(crop_data[[target]])\n",
    "scaler_dict[target] = target_scaler\n",
    "\n",
    "def create_sequences_all(data, features, target, look_back=9):\n",
    "    X, y = [], []\n",
    "    areas = data['Area'].unique()\n",
    "    for area in areas:\n",
    "        region_data = data[data['Area'] == area].sort_values('Year')\n",
    "        for i in range(look_back, len(region_data)):\n",
    "            X.append(region_data[features].iloc[i-look_back:i].values)\n",
    "            y.append(region_data[target].iloc[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(\"Membuat sequence data untuk training dan testing...\")\n",
    "X, y = create_sequences_all(crop_data, features, target, look_back=look_back)\n",
    "X_rf = X.reshape(X.shape[0], -1)\n",
    "# Split for all models: 70% train, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Jumlah data training: {X_train.shape[0]}\")\n",
    "print(f\"Jumlah data testing: {X_test.shape[0]}\")\n",
    "X_train_rf = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_rf = X_test.reshape(X_test.shape[0], -1)\n",
    "predictions = {}\n",
    "\n",
    "# Model Definitions\n",
    "print(\"[INFO] Mulai training SimpleRNN...\")\n",
    "def build_rnn_model(units=64, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        SimpleRNN(units, activation='tanh'),\n",
    "        Dropout(dropout),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV SimpleRNN...\")\n",
    "rnn_reg = KerasRegressor(model=build_rnn_model, verbose=0)\n",
    "rnn_grid = GridSearchCV(rnn_reg, rnn_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "rnn_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] SimpleRNN selesai training. Evaluasi...\")\n",
    "rnn_best = rnn_grid.best_estimator_\n",
    "y_pred = rnn_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'SimpleRNN',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rnn_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi SimpleRNN selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training LSTM...\")\n",
    "def build_lstm_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        LSTM(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        LSTM(units2, activation='tanh'),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV LSTM...\")\n",
    "lstm_reg = KerasRegressor(model=build_lstm_model, verbose=0)\n",
    "lstm_grid = GridSearchCV(lstm_reg, lstm_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "lstm_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] LSTM selesai training. Evaluasi...\")\n",
    "lstm_best = lstm_grid.best_estimator_\n",
    "y_pred = lstm_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'LSTM',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(lstm_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi LSTM selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GRU...\")\n",
    "def build_gru_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        GRU(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        GRU(units2),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV GRU...\")\n",
    "gru_reg = KerasRegressor(model=build_gru_model, verbose=0)\n",
    "gru_grid = GridSearchCV(gru_reg, gru_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "gru_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] GRU selesai training. Evaluasi...\")\n",
    "gru_best = gru_grid.best_estimator_\n",
    "y_pred = gru_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GRU',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gru_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GRU selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training RandomForest...\")\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV RandomForest...\")\n",
    "rf_grid = GridSearchCV(rf, rf_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] RandomForest selesai training. Evaluasi...\")\n",
    "rf_best = rf_grid.best_estimator_\n",
    "y_pred = rf_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'RandomForest',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rf_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi RandomForest selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training BaggingRegressor...\")\n",
    "bag_param_grid = {\n",
    "    'estimator': [RandomForestRegressor(max_depth=3), RandomForestRegressor(max_depth=5)],\n",
    "    'n_estimators': [10, 20, 50]\n",
    "}\n",
    "bag = BaggingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV BaggingRegressor...\")\n",
    "bag_grid = GridSearchCV(bag, bag_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] BaggingRegressor selesai training. Evaluasi...\")\n",
    "bag_best = bag_grid.best_estimator_\n",
    "y_pred = bag_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'BaggingRegressor',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(bag_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi BaggingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GradientBoostingRegressor...\")\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV GradientBoostingRegressor...\")\n",
    "gb_grid = GridSearchCV(gb, gb_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "gb_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] GradientBoostingRegressor selesai training. Evaluasi...\")\n",
    "gb_best = gb_grid.best_estimator_\n",
    "y_pred = gb_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GradientBoosting',\n",
    "    'category': 'Boosting',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gb_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GradientBoostingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de7253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = \"Sorghum\"\n",
    "print(f\"\\n=== Mulai proses untuk crop: {item} ===\")\n",
    "\n",
    "crop_data = data[data['Item'] == item].dropna().sort_values(['Area', 'Year'])\n",
    "crop_data = remove_outliers(crop_data, 'hg/ha_yield')\n",
    "crop_data['log_yield'] = np.log(crop_data['hg/ha_yield'] + 1)\n",
    "crop_data['rolling_yield_mean3'] = crop_data.groupby('Area')['hg/ha_yield'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "scaler_rolling = MinMaxScaler()\n",
    "crop_data['rolling_yield_mean3'] = scaler_rolling.fit_transform(crop_data[['rolling_yield_mean3']])\n",
    "scaler_dict = {}\n",
    "for col in features:\n",
    "    scaler = MinMaxScaler()\n",
    "    crop_data[col] = scaler.fit_transform(crop_data[[col]])\n",
    "    scaler_dict[col] = scaler\n",
    "target_scaler = MinMaxScaler()\n",
    "crop_data[target] = target_scaler.fit_transform(crop_data[[target]])\n",
    "scaler_dict[target] = target_scaler\n",
    "\n",
    "def create_sequences_all(data, features, target, look_back=9):\n",
    "    X, y = [], []\n",
    "    areas = data['Area'].unique()\n",
    "    for area in areas:\n",
    "        region_data = data[data['Area'] == area].sort_values('Year')\n",
    "        for i in range(look_back, len(region_data)):\n",
    "            X.append(region_data[features].iloc[i-look_back:i].values)\n",
    "            y.append(region_data[target].iloc[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(\"Membuat sequence data untuk training dan testing...\")\n",
    "X, y = create_sequences_all(crop_data, features, target, look_back=look_back)\n",
    "X_rf = X.reshape(X.shape[0], -1)\n",
    "# Split for all models: 70% train, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Jumlah data training: {X_train.shape[0]}\")\n",
    "print(f\"Jumlah data testing: {X_test.shape[0]}\")\n",
    "X_train_rf = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_rf = X_test.reshape(X_test.shape[0], -1)\n",
    "predictions = {}\n",
    "\n",
    "# Model Definitions\n",
    "print(\"[INFO] Mulai training SimpleRNN...\")\n",
    "def build_rnn_model(units=64, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        SimpleRNN(units, activation='tanh'),\n",
    "        Dropout(dropout),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV SimpleRNN...\")\n",
    "rnn_reg = KerasRegressor(model=build_rnn_model, verbose=0)\n",
    "rnn_grid = GridSearchCV(rnn_reg, rnn_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "rnn_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] SimpleRNN selesai training. Evaluasi...\")\n",
    "rnn_best = rnn_grid.best_estimator_\n",
    "y_pred = rnn_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'SimpleRNN',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rnn_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi SimpleRNN selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training LSTM...\")\n",
    "def build_lstm_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        LSTM(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        LSTM(units2, activation='tanh'),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV LSTM...\")\n",
    "lstm_reg = KerasRegressor(model=build_lstm_model, verbose=0)\n",
    "lstm_grid = GridSearchCV(lstm_reg, lstm_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "lstm_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] LSTM selesai training. Evaluasi...\")\n",
    "lstm_best = lstm_grid.best_estimator_\n",
    "y_pred = lstm_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'LSTM',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(lstm_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi LSTM selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GRU...\")\n",
    "def build_gru_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        GRU(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        GRU(units2),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV GRU...\")\n",
    "gru_reg = KerasRegressor(model=build_gru_model, verbose=0)\n",
    "gru_grid = GridSearchCV(gru_reg, gru_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "gru_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] GRU selesai training. Evaluasi...\")\n",
    "gru_best = gru_grid.best_estimator_\n",
    "y_pred = gru_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GRU',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gru_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GRU selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training RandomForest...\")\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV RandomForest...\")\n",
    "rf_grid = GridSearchCV(rf, rf_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] RandomForest selesai training. Evaluasi...\")\n",
    "rf_best = rf_grid.best_estimator_\n",
    "y_pred = rf_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'RandomForest',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rf_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi RandomForest selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training BaggingRegressor...\")\n",
    "bag_param_grid = {\n",
    "    'estimator': [RandomForestRegressor(max_depth=3), RandomForestRegressor(max_depth=5)],\n",
    "    'n_estimators': [10, 20, 50]\n",
    "}\n",
    "bag = BaggingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV BaggingRegressor...\")\n",
    "bag_grid = GridSearchCV(bag, bag_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] BaggingRegressor selesai training. Evaluasi...\")\n",
    "bag_best = bag_grid.best_estimator_\n",
    "y_pred = bag_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'BaggingRegressor',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(bag_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi BaggingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GradientBoostingRegressor...\")\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV GradientBoostingRegressor...\")\n",
    "gb_grid = GridSearchCV(gb, gb_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "gb_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] GradientBoostingRegressor selesai training. Evaluasi...\")\n",
    "gb_best = gb_grid.best_estimator_\n",
    "y_pred = gb_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GradientBoosting',\n",
    "    'category': 'Boosting',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gb_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GradientBoostingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ada27",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = \"Soybeans\"\n",
    "print(f\"\\n=== Mulai proses untuk crop: {item} ===\")\n",
    "\n",
    "crop_data = data[data['Item'] == item].dropna().sort_values(['Area', 'Year'])\n",
    "crop_data = remove_outliers(crop_data, 'hg/ha_yield')\n",
    "crop_data['log_yield'] = np.log(crop_data['hg/ha_yield'] + 1)\n",
    "crop_data['rolling_yield_mean3'] = crop_data.groupby('Area')['hg/ha_yield'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "scaler_rolling = MinMaxScaler()\n",
    "crop_data['rolling_yield_mean3'] = scaler_rolling.fit_transform(crop_data[['rolling_yield_mean3']])\n",
    "scaler_dict = {}\n",
    "for col in features:\n",
    "    scaler = MinMaxScaler()\n",
    "    crop_data[col] = scaler.fit_transform(crop_data[[col]])\n",
    "    scaler_dict[col] = scaler\n",
    "target_scaler = MinMaxScaler()\n",
    "crop_data[target] = target_scaler.fit_transform(crop_data[[target]])\n",
    "scaler_dict[target] = target_scaler\n",
    "\n",
    "def create_sequences_all(data, features, target, look_back=9):\n",
    "    X, y = [], []\n",
    "    areas = data['Area'].unique()\n",
    "    for area in areas:\n",
    "        region_data = data[data['Area'] == area].sort_values('Year')\n",
    "        for i in range(look_back, len(region_data)):\n",
    "            X.append(region_data[features].iloc[i-look_back:i].values)\n",
    "            y.append(region_data[target].iloc[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(\"Membuat sequence data untuk training dan testing...\")\n",
    "X, y = create_sequences_all(crop_data, features, target, look_back=look_back)\n",
    "X_rf = X.reshape(X.shape[0], -1)\n",
    "# Split for all models: 70% train, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Jumlah data training: {X_train.shape[0]}\")\n",
    "print(f\"Jumlah data testing: {X_test.shape[0]}\")\n",
    "X_train_rf = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_rf = X_test.reshape(X_test.shape[0], -1)\n",
    "predictions = {}\n",
    "\n",
    "# Model Definitions\n",
    "print(\"[INFO] Mulai training SimpleRNN...\")\n",
    "def build_rnn_model(units=64, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        SimpleRNN(units, activation='tanh'),\n",
    "        Dropout(dropout),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV SimpleRNN...\")\n",
    "rnn_reg = KerasRegressor(model=build_rnn_model, verbose=0)\n",
    "rnn_grid = GridSearchCV(rnn_reg, rnn_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "rnn_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] SimpleRNN selesai training. Evaluasi...\")\n",
    "rnn_best = rnn_grid.best_estimator_\n",
    "y_pred = rnn_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'SimpleRNN',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rnn_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi SimpleRNN selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training LSTM...\")\n",
    "def build_lstm_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        LSTM(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        LSTM(units2, activation='tanh'),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV LSTM...\")\n",
    "lstm_reg = KerasRegressor(model=build_lstm_model, verbose=0)\n",
    "lstm_grid = GridSearchCV(lstm_reg, lstm_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "lstm_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] LSTM selesai training. Evaluasi...\")\n",
    "lstm_best = lstm_grid.best_estimator_\n",
    "y_pred = lstm_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'LSTM',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(lstm_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi LSTM selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GRU...\")\n",
    "def build_gru_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        GRU(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        GRU(units2),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV GRU...\")\n",
    "gru_reg = KerasRegressor(model=build_gru_model, verbose=0)\n",
    "gru_grid = GridSearchCV(gru_reg, gru_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "gru_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] GRU selesai training. Evaluasi...\")\n",
    "gru_best = gru_grid.best_estimator_\n",
    "y_pred = gru_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GRU',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gru_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GRU selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training RandomForest...\")\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV RandomForest...\")\n",
    "rf_grid = GridSearchCV(rf, rf_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] RandomForest selesai training. Evaluasi...\")\n",
    "rf_best = rf_grid.best_estimator_\n",
    "y_pred = rf_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'RandomForest',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rf_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi RandomForest selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training BaggingRegressor...\")\n",
    "bag_param_grid = {\n",
    "    'estimator': [RandomForestRegressor(max_depth=3), RandomForestRegressor(max_depth=5)],\n",
    "    'n_estimators': [10, 20, 50]\n",
    "}\n",
    "bag = BaggingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV BaggingRegressor...\")\n",
    "bag_grid = GridSearchCV(bag, bag_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] BaggingRegressor selesai training. Evaluasi...\")\n",
    "bag_best = bag_grid.best_estimator_\n",
    "y_pred = bag_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'BaggingRegressor',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(bag_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi BaggingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GradientBoostingRegressor...\")\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV GradientBoostingRegressor...\")\n",
    "gb_grid = GridSearchCV(gb, gb_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "gb_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] GradientBoostingRegressor selesai training. Evaluasi...\")\n",
    "gb_best = gb_grid.best_estimator_\n",
    "y_pred = gb_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GradientBoosting',\n",
    "    'category': 'Boosting',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gb_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GradientBoostingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb8faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = \"Sweet potatoes\"\n",
    "print(f\"\\n=== Mulai proses untuk crop: {item} ===\")\n",
    "\n",
    "crop_data = data[data['Item'] == item].dropna().sort_values(['Area', 'Year'])\n",
    "crop_data = remove_outliers(crop_data, 'hg/ha_yield')\n",
    "crop_data['log_yield'] = np.log(crop_data['hg/ha_yield'] + 1)\n",
    "crop_data['rolling_yield_mean3'] = crop_data.groupby('Area')['hg/ha_yield'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "scaler_rolling = MinMaxScaler()\n",
    "crop_data['rolling_yield_mean3'] = scaler_rolling.fit_transform(crop_data[['rolling_yield_mean3']])\n",
    "scaler_dict = {}\n",
    "for col in features:\n",
    "    scaler = MinMaxScaler()\n",
    "    crop_data[col] = scaler.fit_transform(crop_data[[col]])\n",
    "    scaler_dict[col] = scaler\n",
    "target_scaler = MinMaxScaler()\n",
    "crop_data[target] = target_scaler.fit_transform(crop_data[[target]])\n",
    "scaler_dict[target] = target_scaler\n",
    "\n",
    "def create_sequences_all(data, features, target, look_back=9):\n",
    "    X, y = [], []\n",
    "    areas = data['Area'].unique()\n",
    "    for area in areas:\n",
    "        region_data = data[data['Area'] == area].sort_values('Year')\n",
    "        for i in range(look_back, len(region_data)):\n",
    "            X.append(region_data[features].iloc[i-look_back:i].values)\n",
    "            y.append(region_data[target].iloc[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(\"Membuat sequence data untuk training dan testing...\")\n",
    "X, y = create_sequences_all(crop_data, features, target, look_back=look_back)\n",
    "X_rf = X.reshape(X.shape[0], -1)\n",
    "# Split for all models: 70% train, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Jumlah data training: {X_train.shape[0]}\")\n",
    "print(f\"Jumlah data testing: {X_test.shape[0]}\")\n",
    "X_train_rf = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_rf = X_test.reshape(X_test.shape[0], -1)\n",
    "predictions = {}\n",
    "\n",
    "# Model Definitions\n",
    "print(\"[INFO] Mulai training SimpleRNN...\")\n",
    "def build_rnn_model(units=64, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        SimpleRNN(units, activation='tanh'),\n",
    "        Dropout(dropout),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV SimpleRNN...\")\n",
    "rnn_reg = KerasRegressor(model=build_rnn_model, verbose=0)\n",
    "rnn_grid = GridSearchCV(rnn_reg, rnn_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "rnn_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] SimpleRNN selesai training. Evaluasi...\")\n",
    "rnn_best = rnn_grid.best_estimator_\n",
    "y_pred = rnn_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'SimpleRNN',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rnn_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi SimpleRNN selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training LSTM...\")\n",
    "def build_lstm_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        LSTM(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        LSTM(units2, activation='tanh'),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV LSTM...\")\n",
    "lstm_reg = KerasRegressor(model=build_lstm_model, verbose=0)\n",
    "lstm_grid = GridSearchCV(lstm_reg, lstm_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "lstm_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] LSTM selesai training. Evaluasi...\")\n",
    "lstm_best = lstm_grid.best_estimator_\n",
    "y_pred = lstm_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'LSTM',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(lstm_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi LSTM selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GRU...\")\n",
    "def build_gru_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        GRU(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        GRU(units2),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV GRU...\")\n",
    "gru_reg = KerasRegressor(model=build_gru_model, verbose=0)\n",
    "gru_grid = GridSearchCV(gru_reg, gru_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "gru_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] GRU selesai training. Evaluasi...\")\n",
    "gru_best = gru_grid.best_estimator_\n",
    "y_pred = gru_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GRU',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gru_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GRU selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training RandomForest...\")\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV RandomForest...\")\n",
    "rf_grid = GridSearchCV(rf, rf_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] RandomForest selesai training. Evaluasi...\")\n",
    "rf_best = rf_grid.best_estimator_\n",
    "y_pred = rf_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'RandomForest',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rf_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi RandomForest selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training BaggingRegressor...\")\n",
    "bag_param_grid = {\n",
    "    'estimator': [RandomForestRegressor(max_depth=3), RandomForestRegressor(max_depth=5)],\n",
    "    'n_estimators': [10, 20, 50]\n",
    "}\n",
    "bag = BaggingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV BaggingRegressor...\")\n",
    "bag_grid = GridSearchCV(bag, bag_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] BaggingRegressor selesai training. Evaluasi...\")\n",
    "bag_best = bag_grid.best_estimator_\n",
    "y_pred = bag_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'BaggingRegressor',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(bag_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi BaggingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GradientBoostingRegressor...\")\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV GradientBoostingRegressor...\")\n",
    "gb_grid = GridSearchCV(gb, gb_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "gb_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] GradientBoostingRegressor selesai training. Evaluasi...\")\n",
    "gb_best = gb_grid.best_estimator_\n",
    "y_pred = gb_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GradientBoosting',\n",
    "    'category': 'Boosting',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gb_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GradientBoostingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb06b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = \"Wheat\"\n",
    "print(f\"\\n=== Mulai proses untuk crop: {item} ===\")\n",
    "\n",
    "crop_data = data[data['Item'] == item].dropna().sort_values(['Area', 'Year'])\n",
    "crop_data = remove_outliers(crop_data, 'hg/ha_yield')\n",
    "crop_data['log_yield'] = np.log(crop_data['hg/ha_yield'] + 1)\n",
    "crop_data['rolling_yield_mean3'] = crop_data.groupby('Area')['hg/ha_yield'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "scaler_rolling = MinMaxScaler()\n",
    "crop_data['rolling_yield_mean3'] = scaler_rolling.fit_transform(crop_data[['rolling_yield_mean3']])\n",
    "scaler_dict = {}\n",
    "for col in features:\n",
    "    scaler = MinMaxScaler()\n",
    "    crop_data[col] = scaler.fit_transform(crop_data[[col]])\n",
    "    scaler_dict[col] = scaler\n",
    "target_scaler = MinMaxScaler()\n",
    "crop_data[target] = target_scaler.fit_transform(crop_data[[target]])\n",
    "scaler_dict[target] = target_scaler\n",
    "\n",
    "def create_sequences_all(data, features, target, look_back=9):\n",
    "    X, y = [], []\n",
    "    areas = data['Area'].unique()\n",
    "    for area in areas:\n",
    "        region_data = data[data['Area'] == area].sort_values('Year')\n",
    "        for i in range(look_back, len(region_data)):\n",
    "            X.append(region_data[features].iloc[i-look_back:i].values)\n",
    "            y.append(region_data[target].iloc[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(\"Membuat sequence data untuk training dan testing...\")\n",
    "X, y = create_sequences_all(crop_data, features, target, look_back=look_back)\n",
    "X_rf = X.reshape(X.shape[0], -1)\n",
    "# Split for all models: 70% train, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Jumlah data training: {X_train.shape[0]}\")\n",
    "print(f\"Jumlah data testing: {X_test.shape[0]}\")\n",
    "X_train_rf = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_rf = X_test.reshape(X_test.shape[0], -1)\n",
    "predictions = {}\n",
    "\n",
    "# Model Definitions\n",
    "print(\"[INFO] Mulai training SimpleRNN...\")\n",
    "def build_rnn_model(units=64, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        SimpleRNN(units, activation='tanh'),\n",
    "        Dropout(dropout),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV SimpleRNN...\")\n",
    "rnn_reg = KerasRegressor(model=build_rnn_model, verbose=0)\n",
    "rnn_grid = GridSearchCV(rnn_reg, rnn_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "rnn_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] SimpleRNN selesai training. Evaluasi...\")\n",
    "rnn_best = rnn_grid.best_estimator_\n",
    "y_pred = rnn_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'SimpleRNN',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rnn_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi SimpleRNN selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training LSTM...\")\n",
    "def build_lstm_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        LSTM(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        LSTM(units2, activation='tanh'),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV LSTM...\")\n",
    "lstm_reg = KerasRegressor(model=build_lstm_model, verbose=0)\n",
    "lstm_grid = GridSearchCV(lstm_reg, lstm_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "lstm_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] LSTM selesai training. Evaluasi...\")\n",
    "lstm_best = lstm_grid.best_estimator_\n",
    "y_pred = lstm_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'LSTM',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(lstm_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi LSTM selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GRU...\")\n",
    "def build_gru_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        GRU(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        GRU(units2),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV GRU...\")\n",
    "gru_reg = KerasRegressor(model=build_gru_model, verbose=0)\n",
    "gru_grid = GridSearchCV(gru_reg, gru_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "gru_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] GRU selesai training. Evaluasi...\")\n",
    "gru_best = gru_grid.best_estimator_\n",
    "y_pred = gru_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GRU',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gru_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GRU selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training RandomForest...\")\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV RandomForest...\")\n",
    "rf_grid = GridSearchCV(rf, rf_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] RandomForest selesai training. Evaluasi...\")\n",
    "rf_best = rf_grid.best_estimator_\n",
    "y_pred = rf_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'RandomForest',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rf_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi RandomForest selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training BaggingRegressor...\")\n",
    "bag_param_grid = {\n",
    "    'estimator': [RandomForestRegressor(max_depth=3), RandomForestRegressor(max_depth=5)],\n",
    "    'n_estimators': [10, 20, 50]\n",
    "}\n",
    "bag = BaggingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV BaggingRegressor...\")\n",
    "bag_grid = GridSearchCV(bag, bag_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] BaggingRegressor selesai training. Evaluasi...\")\n",
    "bag_best = bag_grid.best_estimator_\n",
    "y_pred = bag_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'BaggingRegressor',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(bag_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi BaggingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GradientBoostingRegressor...\")\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV GradientBoostingRegressor...\")\n",
    "gb_grid = GridSearchCV(gb, gb_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "gb_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] GradientBoostingRegressor selesai training. Evaluasi...\")\n",
    "gb_best = gb_grid.best_estimator_\n",
    "y_pred = gb_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GradientBoosting',\n",
    "    'category': 'Boosting',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gb_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GradientBoostingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f37a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = \"Yams\"\n",
    "print(f\"\\n=== Mulai proses untuk crop: {item} ===\")\n",
    "\n",
    "crop_data = data[data['Item'] == item].dropna().sort_values(['Area', 'Year'])\n",
    "crop_data = remove_outliers(crop_data, 'hg/ha_yield')\n",
    "crop_data['log_yield'] = np.log(crop_data['hg/ha_yield'] + 1)\n",
    "crop_data['rolling_yield_mean3'] = crop_data.groupby('Area')['hg/ha_yield'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "scaler_rolling = MinMaxScaler()\n",
    "crop_data['rolling_yield_mean3'] = scaler_rolling.fit_transform(crop_data[['rolling_yield_mean3']])\n",
    "scaler_dict = {}\n",
    "for col in features:\n",
    "    scaler = MinMaxScaler()\n",
    "    crop_data[col] = scaler.fit_transform(crop_data[[col]])\n",
    "    scaler_dict[col] = scaler\n",
    "target_scaler = MinMaxScaler()\n",
    "crop_data[target] = target_scaler.fit_transform(crop_data[[target]])\n",
    "scaler_dict[target] = target_scaler\n",
    "\n",
    "def create_sequences_all(data, features, target, look_back=9):\n",
    "    X, y = [], []\n",
    "    areas = data['Area'].unique()\n",
    "    for area in areas:\n",
    "        region_data = data[data['Area'] == area].sort_values('Year')\n",
    "        for i in range(look_back, len(region_data)):\n",
    "            X.append(region_data[features].iloc[i-look_back:i].values)\n",
    "            y.append(region_data[target].iloc[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(\"Membuat sequence data untuk training dan testing...\")\n",
    "X, y = create_sequences_all(crop_data, features, target, look_back=look_back)\n",
    "X_rf = X.reshape(X.shape[0], -1)\n",
    "# Split for all models: 70% train, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f\"Jumlah data training: {X_train.shape[0]}\")\n",
    "print(f\"Jumlah data testing: {X_test.shape[0]}\")\n",
    "X_train_rf = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_rf = X_test.reshape(X_test.shape[0], -1)\n",
    "predictions = {}\n",
    "\n",
    "# Model Definitions\n",
    "print(\"[INFO] Mulai training SimpleRNN...\")\n",
    "def build_rnn_model(units=64, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        SimpleRNN(units, activation='tanh'),\n",
    "        Dropout(dropout),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV SimpleRNN...\")\n",
    "rnn_reg = KerasRegressor(model=build_rnn_model, verbose=0)\n",
    "rnn_grid = GridSearchCV(rnn_reg, rnn_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "rnn_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] SimpleRNN selesai training. Evaluasi...\")\n",
    "rnn_best = rnn_grid.best_estimator_\n",
    "y_pred = rnn_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'SimpleRNN',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rnn_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi SimpleRNN selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training LSTM...\")\n",
    "def build_lstm_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        LSTM(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        LSTM(units2, activation='tanh'),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV LSTM...\")\n",
    "lstm_reg = KerasRegressor(model=build_lstm_model, verbose=0)\n",
    "lstm_grid = GridSearchCV(lstm_reg, lstm_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "lstm_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] LSTM selesai training. Evaluasi...\")\n",
    "lstm_best = lstm_grid.best_estimator_\n",
    "y_pred = lstm_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'LSTM',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(lstm_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi LSTM selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GRU...\")\n",
    "def build_gru_model(units1=64, units2=32, dropout=0.2, lr=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(look_back, len(features))),\n",
    "        GRU(units1, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout),\n",
    "        GRU(units2),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "print(\"[INFO] GridSearchCV GRU...\")\n",
    "gru_reg = KerasRegressor(model=build_gru_model, verbose=0)\n",
    "gru_grid = GridSearchCV(gru_reg, gru_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "gru_grid.fit(X_train, y_train)\n",
    "print(\"[INFO] GRU selesai training. Evaluasi...\")\n",
    "gru_best = gru_grid.best_estimator_\n",
    "y_pred = gru_best.predict(X_test)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GRU',\n",
    "    'category': 'Deep Learning',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gru_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GRU selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training RandomForest...\")\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV RandomForest...\")\n",
    "rf_grid = GridSearchCV(rf, rf_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] RandomForest selesai training. Evaluasi...\")\n",
    "rf_best = rf_grid.best_estimator_\n",
    "y_pred = rf_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'RandomForest',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(rf_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi RandomForest selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training BaggingRegressor...\")\n",
    "bag_param_grid = {\n",
    "    'estimator': [RandomForestRegressor(max_depth=3), RandomForestRegressor(max_depth=5)],\n",
    "    'n_estimators': [10, 20, 50]\n",
    "}\n",
    "bag = BaggingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV BaggingRegressor...\")\n",
    "bag_grid = GridSearchCV(bag, bag_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] BaggingRegressor selesai training. Evaluasi...\")\n",
    "bag_best = bag_grid.best_estimator_\n",
    "y_pred = bag_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'BaggingRegressor',\n",
    "    'category': 'Tree Ensemble',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(bag_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi BaggingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")\n",
    "\n",
    "print(\"[INFO] Mulai training GradientBoostingRegressor...\")\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "print(\"[INFO] GridSearchCV GradientBoostingRegressor...\")\n",
    "gb_grid = GridSearchCV(gb, gb_param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "gb_grid.fit(X_train_rf, y_train)\n",
    "print(\"[INFO] GradientBoostingRegressor selesai training. Evaluasi...\")\n",
    "gb_best = gb_grid.best_estimator_\n",
    "y_pred = gb_best.predict(X_test_rf)\n",
    "y_pred = scaler_dict[target].inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_true = scaler_dict[target].inverse_transform(y_test.reshape(-1, 1))\n",
    "all_results.append({\n",
    "    'item': item,\n",
    "    'model': 'GradientBoosting',\n",
    "    'category': 'Boosting',\n",
    "    'mae': float(mean_absolute_error(y_true, y_pred)),\n",
    "    'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': float(r2_score(y_true, y_pred)),\n",
    "    'best_params': str(gb_grid.best_params_)\n",
    "})\n",
    "print(f\"[INFO] Evaluasi GradientBoostingRegressor selesai.\\nMAE: {float(mean_absolute_error(y_true, y_pred))}, MSE: {float(mean_squared_error(y_true, y_pred))}, R²: {float(r2_score(y_true, y_pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d850a30c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 1. Histogram Yield\u001b[39;00m\n\u001b[32m      9\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m,\u001b[32m6\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m sns.histplot(\u001b[43mdata\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mhg/ha_yield\u001b[39m\u001b[33m'\u001b[39m], bins=\u001b[32m30\u001b[39m, kde=\u001b[38;5;28;01mTrue\u001b[39;00m, color=\u001b[33m'\u001b[39m\u001b[33mskyblue\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     11\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mDistribusi Yield (hg/ha_yield)\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     12\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mYield (hg/ha)\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Evaluation Visualization\n",
    "results_dir = 'results/all_models'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# 1. Histogram Yield\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(data['hg/ha_yield'], bins=30, kde=True, color='skyblue')\n",
    "plt.title('Distribusi Yield (hg/ha_yield)')\n",
    "plt.xlabel('Yield (hg/ha)')\n",
    "plt.ylabel('Frekuensi')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '1_hist_yield_distribution.png'))\n",
    "plt.close()\n",
    "\n",
    "# 2. Korelasi Heatmap\n",
    "plt.figure(figsize=(10,8))\n",
    "num_cols = data.select_dtypes(include='number').columns\n",
    "corr = data[num_cols].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', square=True)\n",
    "plt.title('Heatmap Korelasi Fitur Numerik')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '2_heatmap_korelasi.png'))\n",
    "plt.close()\n",
    "\n",
    "# 3. Jumlah Data per Area (Encoded)\n",
    "plt.figure(figsize=(14,6))\n",
    "area_counts = data['Area'].value_counts().sort_values(ascending=False)\n",
    "sns.barplot(x=area_counts.index, y=area_counts.values, palette='viridis')\n",
    "plt.title('Jumlah Data per Area')\n",
    "plt.xlabel('Area (Encoded)')\n",
    "plt.ylabel('Jumlah Data')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '3_countplot_area.png'))\n",
    "plt.close()\n",
    "\n",
    "# 4. Boxplot Yield per Crop\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x='Item', y='hg/ha_yield', data=data, palette='Set2')\n",
    "plt.title('Boxplot Yield per Crop')\n",
    "plt.xlabel('Crop (Item)')\n",
    "plt.ylabel('Yield (hg/ha)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '4_boxplot_yield_per_crop.png'))\n",
    "plt.close()\n",
    "\n",
    "# 5. R² Score Tiap Model per Crop\n",
    "df_results = pd.DataFrame(all_results)\n",
    "plt.figure(figsize=(14,7))\n",
    "sns.barplot(data=df_results, x='item', y='r2', hue='model', ci=None)\n",
    "plt.title('R² Score Tiap Model per Crop')\n",
    "plt.ylabel('R² Score')\n",
    "plt.xlabel('Crop (Item)')\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '5_r2score_per_model_crop.png'))\n",
    "plt.close()\n",
    "\n",
    "# 6. Rata-rata R² Score per Model\n",
    "plt.figure(figsize=(10,6))\n",
    "avg_r2 = df_results.groupby('model')['r2'].mean().sort_values(ascending=False)\n",
    "sns.barplot(x=avg_r2.index, y=avg_r2.values, palette='Blues_d')\n",
    "plt.title('Rata-rata R² Score per Model')\n",
    "plt.ylabel('Rata-rata R²')\n",
    "plt.xlabel('Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '6_avg_r2_score_per_model.png'))\n",
    "plt.close()\n",
    "\n",
    "# 7. Rata-rata MAE per Model\n",
    "plt.figure(figsize=(10,6))\n",
    "avg_mae = df_results.groupby('model')['mae'].mean().sort_values()\n",
    "sns.barplot(x=avg_mae.index, y=avg_mae.values, palette='Reds')\n",
    "plt.title('Rata-rata MAE per Model')\n",
    "plt.ylabel('Rata-rata MAE')\n",
    "plt.xlabel('Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, '7_avg_mae_per_model.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8030aa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Save model evaluation results to CSV\n",
    "csv_path = os.path.join(results_dir, 'model_results_per_item_gridsearch.csv')\n",
    "all_results_sorted = sorted(all_results, key=lambda x: (x['item'], x['mae']))\n",
    "with open(csv_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Item', 'Model', 'Category', 'MAE', 'MSE', 'R2', 'Best_Params'])\n",
    "    for res in all_results_sorted:\n",
    "        writer.writerow([res['item'], res['model'], res['category'], res['mae'], res['mse'], res['r2'], res['best_params']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
